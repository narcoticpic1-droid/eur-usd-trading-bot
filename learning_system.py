import sqlite3
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import joblib
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.preprocessing import StandardScaler
import logging
import os

class AdaptiveLearningSystem:
    """
    Ø³ÛŒØ³ØªÙ… ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ ØªØ·Ø¨ÛŒÙ‚ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Forex
    """
    
    def __init__(self, db_path: str = "forex_learning.db"):
        self.db_path = db_path
        self.models = {}
        self.scalers = {}
        self.performance_history = {}
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
        self.min_samples_for_training = 50
        self.retrain_frequency_days = 7
        self.confidence_threshold = 0.6
        
        # Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡
        self._init_database()
        
        # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ML
        self._init_models()
        
        logging.info("ğŸ§  Ø³ÛŒØ³ØªÙ… ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ ØªØ·Ø¨ÛŒÙ‚ÛŒ Forex Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")

    def _init_database(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ø¬Ø¯ÙˆÙ„ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ Ùˆ Ù†ØªØ§ÛŒØ¬
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS signal_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    pair TEXT NOT NULL,
                    signal_type TEXT,
                    entry_price REAL,
                    exit_price REAL,
                    profit_loss_pips REAL,
                    success BOOLEAN,
                    confidence REAL,
                    market_conditions TEXT,
                    technical_features TEXT,
                    session_type TEXT,
                    volatility REAL,
                    spread REAL,
                    news_impact TEXT
                )
            ''')
            
            # Ø¬Ø¯ÙˆÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS model_performance (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    pair TEXT NOT NULL,
                    model_type TEXT,
                    accuracy REAL,
                    precision_score REAL,
                    recall_score REAL,
                    total_predictions INTEGER,
                    successful_predictions INTEGER
                )
            ''')
            
            # Ø¬Ø¯ÙˆÙ„ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ÛŒ
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS adaptive_parameters (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    pair TEXT NOT NULL,
                    parameter_name TEXT,
                    parameter_value REAL,
                    performance_impact REAL
                )
            ''')
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ: {e}")

    def _init_models(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†"""
        try:
            # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø±Ø§ÛŒ Ø§Ù†ÙˆØ§Ø¹ Ø³ÛŒÚ¯Ù†Ø§Ù„
            self.model_configs = {
                'trend_following': {
                    'model': RandomForestClassifier(n_estimators=100, random_state=42),
                    'features': ['ema_trend', 'macd_signal', 'rsi_value', 'atr_ratio', 'session_strength']
                },
                'reversal': {
                    'model': GradientBoostingClassifier(n_estimators=100, random_state=42),
                    'features': ['support_resistance_distance', 'rsi_extreme', 'divergence', 'volume_spike']
                },
                'breakout': {
                    'model': RandomForestClassifier(n_estimators=150, random_state=42),
                    'features': ['consolidation_time', 'volume_increase', 'volatility_expansion', 'news_impact']
                }
            }
            
            # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡
            self._load_saved_models()
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§: {e}")

    def _load_saved_models(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡"""
        models_dir = "saved_models"
        if not os.path.exists(models_dir):
            os.makedirs(models_dir)
            return
            
        for model_type in self.model_configs.keys():
            model_path = f"{models_dir}/{model_type}_model.joblib"
            scaler_path = f"{models_dir}/{model_type}_scaler.joblib"
            
            if os.path.exists(model_path) and os.path.exists(scaler_path):
                try:
                    self.models[model_type] = joblib.load(model_path)
                    self.scalers[model_type] = joblib.load(scaler_path)
                    logging.info(f"Ù…Ø¯Ù„ {model_type} Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
                except Exception as e:
                    logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ {model_type}: {e}")

    def record_signal_result(self, signal_data: Dict, result_data: Dict):
        """Ø«Ø¨Øª Ù†ØªÛŒØ¬Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO signal_results (
                    pair, signal_type, entry_price, exit_price, 
                    profit_loss_pips, success, confidence, 
                    market_conditions, technical_features, session_type,
                    volatility, spread, news_impact
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                signal_data.get('pair', 'EUR/USD'),
                signal_data.get('signal_type', ''),
                signal_data.get('entry_price', 0),
                result_data.get('exit_price', 0),
                result_data.get('profit_loss_pips', 0),
                result_data.get('success', False),
                signal_data.get('confidence', 0),
                str(signal_data.get('market_conditions', {})),
                str(signal_data.get('technical_features', {})),
                signal_data.get('session_type', ''),
                signal_data.get('volatility', 0),
                signal_data.get('spread', 0),
                signal_data.get('news_impact', '')
            ))
            
            conn.commit()
            conn.close()
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ
            self._check_retrain_trigger(signal_data.get('pair', 'EUR/USD'))
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø«Ø¨Øª Ù†ØªÛŒØ¬Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„: {e}")

    def predict_signal_success(self, signal_data: Dict) -> float:
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ Ù…ÙˆÙÙ‚ÛŒØª Ø³ÛŒÚ¯Ù†Ø§Ù„"""
        try:
            signal_type = signal_data.get('signal_type', 'trend_following')
            pair = signal_data.get('pair', 'EUR/USD')
            
            # Ø§Ú¯Ø± Ù…Ø¯Ù„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ØŒ Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
            if signal_type not in self.models:
                return 0.7  # Ø§Ø­ØªÙ…Ø§Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
            features = self._extract_features(signal_data, signal_type)
            if features is None:
                return 0.7
            
            # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
            model = self.models[signal_type]
            scaler = self.scalers.get(signal_type)
            
            if scaler:
                features_scaled = scaler.transform([features])
            else:
                features_scaled = [features]
            
            # Ø§Ø­ØªÙ…Ø§Ù„ Ú©Ù„Ø§Ø³ Ù…Ø«Ø¨Øª (Ù…ÙˆÙÙ‚ÛŒØª)
            probabilities = model.predict_proba(features_scaled)
            success_probability = probabilities[0][1] if len(probabilities[0]) > 1 else 0.7
            
            return float(success_probability)
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÙˆÙÙ‚ÛŒØª Ø³ÛŒÚ¯Ù†Ø§Ù„: {e}")
            return 0.7

    def get_adaptive_parameters(self, pair: str = 'EUR/USD') -> Dict:
        """Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬ÙØª Ø§Ø±Ø²"""
        try:
            # Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            default_params = {
                'confidence_threshold': 0.6,
                'risk_multiplier': 1.0,
                'leverage_adjustment': 1.0,
                'stop_loss_multiplier': 1.0,
                'take_profit_multiplier': 1.0
            }
            
            # Ø¯Ø±ÛŒØ§ÙØª Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ø®ÛŒØ±
            recent_performance = self._get_recent_performance(pair)
            
            if not recent_performance:
                return default_params
            
            # ØªÙ†Ø¸ÛŒÙ… Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù…Ù„Ú©Ø±Ø¯
            win_rate = recent_performance['win_rate']
            avg_profit = recent_performance['avg_profit_pips']
            
            adaptive_params = default_params.copy()
            
            # ØªÙ†Ø¸ÛŒÙ… Ø¢Ø³ØªØ§Ù†Ù‡ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
            if win_rate > 0.8:
                adaptive_params['confidence_threshold'] = 0.5  # Ú©Ø§Ù‡Ø´ Ø¢Ø³ØªØ§Ù†Ù‡
            elif win_rate < 0.4:
                adaptive_params['confidence_threshold'] = 0.8  # Ø§ÙØ²Ø§ÛŒØ´ Ø¢Ø³ØªØ§Ù†Ù‡
            
            # ØªÙ†Ø¸ÛŒÙ… Ø±ÛŒØ³Ú©
            if win_rate > 0.7 and avg_profit > 10:
                adaptive_params['risk_multiplier'] = 1.2
            elif win_rate < 0.5:
                adaptive_params['risk_multiplier'] = 0.8
            
            # ØªÙ†Ø¸ÛŒÙ… Ø§Ù‡Ø±Ù…
            if recent_performance['max_drawdown'] > 5:  # 5% drawdown
                adaptive_params['leverage_adjustment'] = 0.8
            elif recent_performance['sharpe_ratio'] > 1.5:
                adaptive_params['leverage_adjustment'] = 1.2
            
            return adaptive_params
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ÛŒ: {e}")
            return {
                'confidence_threshold': 0.6,
                'risk_multiplier': 1.0,
                'leverage_adjustment': 1.0,
                'stop_loss_multiplier': 1.0,
                'take_profit_multiplier': 1.0
            }

    def _extract_features(self, signal_data: Dict, signal_type: str) -> Optional[List[float]]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ ML"""
        try:
            feature_names = self.model_configs[signal_type]['features']
            features = []
            
            technical_data = signal_data.get('technical_features', {})
            market_data = signal_data.get('market_conditions', {})
            
            for feature_name in feature_names:
                if feature_name == 'ema_trend':
                    features.append(technical_data.get('ema_trend_strength', 0))
                elif feature_name == 'macd_signal':
                    features.append(technical_data.get('macd_histogram', 0))
                elif feature_name == 'rsi_value':
                    features.append(technical_data.get('rsi', 50))
                elif feature_name == 'atr_ratio':
                    features.append(technical_data.get('atr_ratio', 1))
                elif feature_name == 'session_strength':
                    features.append(self._calculate_session_strength(signal_data))
                elif feature_name == 'support_resistance_distance':
                    features.append(technical_data.get('sr_distance', 0))
                elif feature_name == 'rsi_extreme':
                    rsi = technical_data.get('rsi', 50)
                    features.append(1 if rsi > 70 or rsi < 30 else 0)
                elif feature_name == 'divergence':
                    features.append(technical_data.get('divergence_score', 0))
                elif feature_name == 'volume_spike':
                    features.append(technical_data.get('volume_ratio', 1))
                elif feature_name == 'consolidation_time':
                    features.append(market_data.get('consolidation_periods', 0))
                elif feature_name == 'volume_increase':
                    features.append(technical_data.get('volume_increase', 0))
                elif feature_name == 'volatility_expansion':
                    features.append(market_data.get('volatility_ratio', 1))
                elif feature_name == 'news_impact':
                    features.append(self._calculate_news_impact(signal_data))
                else:
                    features.append(0)  # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            
            return features if len(features) == len(feature_names) else None
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: {e}")
            return None

    def _calculate_session_strength(self, signal_data: Dict) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‚Ø¯Ø±Øª Ø³Ø´Ù† Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ"""
        session = signal_data.get('session_type', '')
        hour = datetime.now().hour
        
        # Ù‚Ø¯Ø±Øª Ø³Ø´Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        if session == 'LONDON' or (7 <= hour <= 16):
            return 0.9
        elif session == 'NEW_YORK' or (13 <= hour <= 22):
            return 0.8
        elif session == 'ASIAN' or (22 <= hour or hour <= 7):
            return 0.6
        else:
            return 0.5

    def _calculate_news_impact(self, signal_data: Dict) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ£Ø«ÛŒØ± Ø§Ø®Ø¨Ø§Ø±"""
        news_impact = signal_data.get('news_impact', '')
        
        if news_impact == 'HIGH':
            return 0.9
        elif news_impact == 'MEDIUM':
            return 0.6
        elif news_impact == 'LOW':
            return 0.3
        else:
            return 0.1

    def _get_recent_performance(self, pair: str, days: int = 30) -> Optional[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ø®ÛŒØ±"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            cutoff_date = datetime.now() - timedelta(days=days)
            
            query = '''
                SELECT success, profit_loss_pips, confidence
                FROM signal_results
                WHERE pair = ? AND timestamp > ?
                ORDER BY timestamp DESC
            '''
            
            df = pd.read_sql_query(query, conn, params=(pair, cutoff_date))
            conn.close()
            
            if df.empty:
                return None
            
            win_rate = df['success'].mean()
            avg_profit = df['profit_loss_pips'].mean()
            max_drawdown = abs(df['profit_loss_pips'].cumsum().min())
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Sharpe ratio Ø³Ø§Ø¯Ù‡
            if df['profit_loss_pips'].std() > 0:
                sharpe_ratio = avg_profit / df['profit_loss_pips'].std()
            else:
                sharpe_ratio = 0
            
            return {
                'win_rate': win_rate,
                'avg_profit_pips': avg_profit,
                'max_drawdown': max_drawdown,
                'sharpe_ratio': sharpe_ratio,
                'total_trades': len(df)
            }
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ø®ÛŒØ±: {e}")
            return None

    def _check_retrain_trigger(self, pair: str):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ù…Ø¯Ù„"""
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT COUNT(*) FROM signal_results 
                WHERE pair = ? AND timestamp > datetime('now', '-7 days')
            ''', (pair,))
            
            recent_count = cursor.fetchone()[0]
            conn.close()
            
            if recent_count >= self.min_samples_for_training:
                self._retrain_models(pair)
                
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ: {e}")

    def _retrain_models(self, pair: str):
        """Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        try:
            logging.info(f"Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ {pair}")
            
            # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ
            training_data = self._prepare_training_data(pair)
            
            if training_data is None or len(training_data) < self.min_samples_for_training:
                logging.warning(f"Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ {pair} Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª")
                return
            
            # Ø¢Ù…ÙˆØ²Ø´ Ù‡Ø± Ù†ÙˆØ¹ Ù…Ø¯Ù„
            for signal_type, config in self.model_configs.items():
                type_data = training_data[training_data['signal_type'] == signal_type]
                
                if len(type_data) < 20:  # Ø­Ø¯Ø§Ù‚Ù„ 20 Ù†Ù…ÙˆÙ†Ù‡
                    continue
                
                self._train_model(signal_type, type_data, config)
            
            logging.info(f"Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ {pair} ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯")
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§: {e}")

    def _prepare_training_data(self, pair: str) -> Optional[pd.DataFrame]:
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            query = '''
                SELECT * FROM signal_results
                WHERE pair = ? AND timestamp > datetime('now', '-90 days')
                ORDER BY timestamp DESC
            '''
            
            df = pd.read_sql_query(query, conn, params=(pair,))
            conn.close()
            
            return df if not df.empty else None
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ: {e}")
            return None

    def _train_model(self, signal_type: str, data: pd.DataFrame, config: Dict):
        """Ø¢Ù…ÙˆØ²Ø´ ÛŒÚ© Ù…Ø¯Ù„ Ø®Ø§Øµ"""
        try:
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§
            features = []
            labels = []
            
            for _, row in data.iterrows():
                try:
                    # ØªØ¨Ø¯ÛŒÙ„ technical_features Ø§Ø² string Ø¨Ù‡ dict
                    tech_features = eval(row['technical_features']) if row['technical_features'] else {}
                    market_conditions = eval(row['market_conditions']) if row['market_conditions'] else {}
                    
                    signal_data = {
                        'technical_features': tech_features,
                        'market_conditions': market_conditions,
                        'session_type': row['session_type'],
                        'news_impact': row['news_impact']
                    }
                    
                    feature_vector = self._extract_features(signal_data, signal_type)
                    if feature_vector:
                        features.append(feature_vector)
                        labels.append(row['success'])
                        
                except:
                    continue
            
            if len(features) < 10:
                return
            
            # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            X_train, X_test, y_train, y_test = train_test_split(
                features, labels, test_size=0.2, random_state=42
            )
            
            # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
            model = config['model']
            model.fit(X_train_scaled, y_train)
            
            # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
            y_pred = model.predict(X_test_scaled)
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, zero_division=0)
            recall = recall_score(y_test, y_pred, zero_division=0)
            
            # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„
            self.models[signal_type] = model
            self.scalers[signal_type] = scaler
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯
            self._save_model_performance(signal_type, accuracy, precision, recall, len(y_test))
            
            # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ø¯Ø± ÙØ§ÛŒÙ„
            self._save_model_to_file(signal_type, model, scaler)
            
            logging.info(f"Ù…Ø¯Ù„ {signal_type} Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯ - Ø¯Ù‚Øª: {accuracy:.3f}")
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ {signal_type}: {e}")

    def _save_model_performance(self, model_type: str, accuracy: float, 
                               precision: float, recall: float, total_predictions: int):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO model_performance (
                    pair, model_type, accuracy, precision_score, 
                    recall_score, total_predictions, successful_predictions
                ) VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                'EUR/USD', model_type, accuracy, precision, recall,
                total_predictions, int(total_predictions * accuracy)
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„: {e}")

    def _save_model_to_file(self, model_type: str, model, scaler):
        """Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ø¯Ø± ÙØ§ÛŒÙ„"""
        try:
            models_dir = "saved_models"
            if not os.path.exists(models_dir):
                os.makedirs(models_dir)
            
            model_path = f"{models_dir}/{model_type}_model.joblib"
            scaler_path = f"{models_dir}/{model_type}_scaler.joblib"
            
            joblib.dump(model, model_path)
            joblib.dump(scaler, scaler_path)
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ø¨Ù‡ ÙØ§ÛŒÙ„: {e}")

    def get_learning_stats(self) -> Dict:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
            cursor = conn.cursor()
            cursor.execute('SELECT COUNT(*) FROM signal_results')
            total_signals = cursor.fetchone()[0]
            
            cursor.execute('SELECT AVG(success) FROM signal_results WHERE timestamp > datetime("now", "-30 days")')
            recent_win_rate = cursor.fetchone()[0] or 0
            
            # Ø¢Ù…Ø§Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§
            model_stats = {}
            for model_type in self.models.keys():
                cursor.execute('''
                    SELECT accuracy, precision_score, recall_score
                    FROM model_performance
                    WHERE model_type = ?
                    ORDER BY timestamp DESC
                    LIMIT 1
                ''', (model_type,))
                
                result = cursor.fetchone()
                if result:
                    model_stats[model_type] = {
                        'accuracy': result[0],
                        'precision': result[1],
                        'recall': result[2]
                    }
            
            conn.close()
            
            return {
                'total_signals_recorded': total_signals,
                'recent_win_rate': recent_win_rate,
                'active_models': list(self.models.keys()),
                'model_performance': model_stats,
                'learning_enabled': True
            }
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ: {e}")
            return {'learning_enabled': False, 'error': str(e)}
